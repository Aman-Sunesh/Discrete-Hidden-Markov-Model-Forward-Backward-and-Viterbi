{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0246437",
   "metadata": {},
   "source": [
    "# Hidden Discrete Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52df29c",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f11f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d581b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for our distribution p(observation|latent). These will be long and\n",
    "# randomized\n",
    "np.random.seed(2)\n",
    "obs_dim = 3\n",
    "GAUSS_MEANS = [np.array([1.0, -1.0, 0.2]),\n",
    "               np.array([0.6, 1.1, 1.0]),\n",
    "               np.array([1.3, 1.0, 1.2])]\n",
    "GAUSS_COVS = [np.eye(obs_dim) / 4]*3\n",
    "PI = np.array([0.7, 0.2, 0.1])\n",
    "A_MAT = np.array([[0.9, 0.0, 0.1], [0.0, 0.9, 0.1], [0.1, 0.3, 0.6]])\n",
    "\n",
    "def generate_latent_and_observations(n_observations: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Generate a sample set of observations along with the true latents.\n",
    "\n",
    "    Args:\n",
    "        n_observations: Number of observations to generate.\n",
    "\n",
    "    Returns:\n",
    "        Sequence of latent states and observations.\n",
    "    \"\"\"\n",
    "    # Placeholders.\n",
    "    latents = np.zeros((n_observations + 1, len(PI)))\n",
    "    observations = np.zeros((n_observations, len(GAUSS_MEANS[0])))\n",
    "\n",
    "    # Start with the initial latent state\n",
    "    latents[0, np.random.choice(np.arange(len(PI)), p=PI)] = 1\n",
    "\n",
    "    # Fill out the rest.\n",
    "    for i in range(n_observations):\n",
    "        latents[i+1, np.random.choice(np.arange(len(PI)), p=A_MAT[np.argmax(latents[i])])] = 1\n",
    "        cur_state = np.argmax(latents[i+1])\n",
    "        observations[i] = np.random.multivariate_normal(GAUSS_MEANS[cur_state], GAUSS_COVS[cur_state])\n",
    "\n",
    "    return latents, observations\n",
    "\n",
    "def observation_probability(latent_index: int, observation: np.ndarray) -> float:\n",
    "    \"\"\"Given an observation and corresponding latent state, evaluate the likelihood.\n",
    "\n",
    "    Args:\n",
    "        latent_index: Index of latent state encoding.\n",
    "        observation: Observation at current time step.\n",
    "\n",
    "    Returns:\n",
    "        Likelihood p(observation|latent).\n",
    "    \"\"\"\n",
    "    # Let's keep things somewhat 'simple' by making our distribution a sum of Gaussians\n",
    "    return stats.multivariate_normal.pdf(observation, mean = GAUSS_MEANS[latent_index], cov = GAUSS_COVS[latent_index])\n",
    "\n",
    "# Generate the data for our study.\n",
    "true_latents, observations = generate_latent_and_observations(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5fcfd",
   "metadata": {},
   "source": [
    "## Emotion Study\n",
    "\n",
    "Your friend in the sociology department is studying the effects of social media habits on emotions. They’ve run an experiment placing FMRI sensors on the brains of several volunteers as they scroll through the internet. The volunteers can be in one of three states: happy, angry, or neutral. They’ve used the following one-hot encoding:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_{\\text{happy}} = \\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}, \\quad\n",
    "\\mathbf{z}_{\\text{angry}} = \\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}, \\quad\n",
    "\\mathbf{z}_{\\text{neutral}} = \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Given that encoding, they also have a very good model for the probability of observing a specific FMRI scan $ \\mathbf{x}_t $ given the state $ \\mathbf{z}_t $. They have already done the favor of uploading it to your notebook as the function `observation_probability`. They also have a time series $ \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_T\\} $ for a volunteer that spends a lot of time on social media. For this volunteer, they know that the transition matrix looks like:\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.0 & 0.1 \\\\\n",
    "0.0 & 0.9 & 0.1 \\\\\n",
    "0.1 & 0.3 & 0.6\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "and having observed the volunteer enter they have a pretty good guess at the initial state:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\pi} = \n",
    "\\begin{bmatrix}\n",
    "0.7 \\\\\n",
    "0.2 \\\\\n",
    "0.1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "They would like to know:\n",
    "\n",
    "- **What is the most likely emotional state at each time step** (i.e. max of $p(z_t | \\mathbf{x}_{1:t})$ or $p(z_t | \\mathbf{x}_{1:T})$)?\n",
    "- **What is the most likely sequence of emotional states expressed by the volunteer?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e0e039",
   "metadata": {},
   "source": [
    "### Part I: Implementing the Viterbi Algorithm for a discrete Hidden Markov Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649513f1",
   "metadata": {},
   "source": [
    "To answer your friend’s questions, you will need to solve for the transition matrix governing the discrete HMM and calculate the most likely series of latent states. This will require:\n",
    "\n",
    "1. Implementing the calculation for `α̂(z_t)`\n",
    "2. Implementing the calculation for `β̂(z_t)`\n",
    "3. Implementing the calculation for `p(z_t | x₁:t)`, `p(z_t | x₁:T)`, `p(z₁:T | x₁:T)`\n",
    "4. Implementing the Viterbi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7c052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
